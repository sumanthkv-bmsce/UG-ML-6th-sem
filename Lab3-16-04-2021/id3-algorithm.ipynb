{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"/kaggle/input/id3-dataset/id3_test_1.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import math\nimport csv\ndef load_csv(filename):\n    lines=csv.reader(open(filename,\"r\"));\n    dataset = list(lines)\n    headers = dataset.pop(0)\n    return dataset,headers\n\nclass Node:\n    def __init__(self,attribute):\n        self.attribute=attribute\n        self.children=[]\n        self.answer=\"\"\n        \ndef subtables(data,col,delete):\n    dic={}\n    coldata=[row[col] for row in data]\n    attr=list(set(coldata))\n    \n    counts=[0]*len(attr)\n    r=len(data)\n    c=len(data[0])\n    for x in range(len(attr)):\n        for y in range(r):\n            if data[y][col]==attr[x]:\n                counts[x]+=1\n        \n    for x in range(len(attr)):\n        dic[attr[x]]=[[0 for i in range(c)] for j in range(counts[x])]\n        pos=0\n        for y in range(r):\n            if data[y][col]==attr[x]:\n                if delete:\n                    del data[y][col]\n                dic[attr[x]][pos]=data[y]\n                pos+=1\n    return attr,dic\n    \ndef entropy(S):\n    attr=list(set(S))\n    if len(attr)==1:\n        return 0\n    \n    counts=[0,0]\n    for i in range(2):\n        counts[i]=sum([1 for x in S if attr[i]==x])/(len(S)*1.0)\n    \n    sums=0\n    for cnt in counts:\n        sums+=-1*cnt*math.log(cnt,2)\n    return sums\n\ndef compute_gain(data,col):\n    attr,dic = subtables(data,col,delete=False)\n    \n    total_size=len(data)\n    entropies=[0]*len(attr)\n    ratio=[0]*len(attr)\n    \n    total_entropy=entropy([row[-1] for row in data])\n    for x in range(len(attr)):\n        ratio[x]=len(dic[attr[x]])/(total_size*1.0)\n        entropies[x]=entropy([row[-1] for row in dic[attr[x]]])\n        total_entropy-=ratio[x]*entropies[x]\n    return total_entropy\n\ndef build_tree(data,features):\n    lastcol=[row[-1] for row in data]\n    if(len(set(lastcol)))==1:\n        node=Node(\"\")\n        node.answer=lastcol[0]\n        return node\n    \n    n=len(data[0])-1\n    gains=[0]*n\n    for col in range(n):\n        gains[col]=compute_gain(data,col)\n    split=gains.index(max(gains))\n    node=Node(features[split])\n    fea = features[:split]+features[split+1:]\n\n    \n    attr,dic=subtables(data,split,delete=True)\n    \n    for x in range(len(attr)):\n        child=build_tree(dic[attr[x]],fea)\n        node.children.append((attr[x],child))\n    return node\n\ndef print_tree(node,level):\n    if node.answer!=\"\":\n        print(\"  \"*level,node.answer)\n        return\n    \n    print(\"  \"*level,node.attribute)\n    for value,n in node.children:\n        print(\"  \"*(level+1),value)\n        print_tree(n,level+2)\n\n        \ndef classify(node,x_test,features):\n    if node.answer!=\"\":\n        print(node.answer)\n        return\n    pos=features.index(node.attribute)\n    for value, n in node.children:\n        if x_test[pos]==value:\n            classify(n,x_test,features)\n            \n'''Main program'''\ndataset,features=load_csv(\"../input/id3-dataset/id3.csv\")\nnode1=build_tree(dataset,features)\n\nprint(\"The decision tree for the dataset using ID3 algorithm is\")\nprint_tree(node1,0)\ntestdata,features=load_csv(\"../input/id3-dataset/id3_test_1.csv\")\n\nfor xtest in testdata:\n    print(\"The test instance:\",xtest)\n    print(\"The label for test instance:\",end=\"   \")\n    classify(node1,xtest,features)","metadata":{"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"The decision tree for the dataset using ID3 algorithm is\n Outlook\n   overcast\n     yes\n   rain\n     Wind\n       strong\n         no\n       weak\n         yes\n   sunny\n     Humidity\n       high\n         no\n       normal\n         yes\nThe test instance: ['rain', 'cool', 'normal', 'strong']\nThe label for test instance:   no\nThe test instance: ['sunny', 'mild', 'normal', 'strong']\nThe label for test instance:   yes\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}